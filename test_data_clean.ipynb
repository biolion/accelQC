{
 "metadata": {
  "name": "",
  "signature": "sha256:b1b3803933d7306dafad4aa168ca9bbfba414683f480d5fa78020864326ed052"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "test_data_clean"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ author: [Ieuan Clay](mailto://ieuan.clay@gmail.com?subject=accelQC)\n",
      "+ started: March 2015\n",
      "+ last update: April 2015\n",
      "\n",
      "test_data_cean is intended to provide some cleaned and organised data for development of QC methods\n",
      "\n",
      "### Functionality provided:\n",
      "+ Data import\n",
      "+ Parsing and reorganisation\n",
      "+ saving in convenient format for re-use\n",
      "\n",
      "### References\n",
      "+ [Rich et al, 2013](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3691227/)\n",
      "+ [Colley et al, 2010](http://www.ncbi.nlm.nih.gov/pubmed/20426228)\n",
      "+ [Markdown basics](https://help.github.com/articles/markdown-basics/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Set up session"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# analytics\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.io as scio\n",
      "import scipy.signal as sp\n",
      "import os\n",
      "\n",
      "# utils\n",
      "from os.path import isfile, join"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# flags\n",
      "TEST = True\n",
      "VERBOSE = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test data path\n",
      "# todo: flexible input\n",
      "if TEST :\n",
      "    datapath = os.path.abspath(\"test_data/\")\n",
      "else :\n",
      "    datapath = os.getcwd()\n",
      "print(datapath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Import data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Overview\n",
      "### Test data\n",
      "+ Test 1 and Test 2 are events with good data.\n",
      "+ Error 1 has the unexpected peaks every 1Hz in the spectrum.\n",
      "+ Error 2 has a bug caused by 32 to 16 bit conversion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_mat_file(f):\n",
      "    \n",
      "    mat = scio.loadmat(f)\n",
      "    # convert to dataframe (see: http://poquitopicante.blogspot.nl/2014/05/loading-matlab-mat-file-into-pandas.html)\n",
      "    # data key name is not consisent, separate from globals, etc\n",
      "    mat = {k:v for k, v in mat.items() if k[0] != '_'}\n",
      "    #tmp = pd.concat([ pd.DataFrame(src: k, pd.DataFrame(v)) for k, v in mat.items() ])\n",
      "    tmp = list()\n",
      "    for k,v in mat.items() : \n",
      "        # depending on shape of data, read it in\n",
      "        if np.shape(v)[0] == 1 :\n",
      "            for i in v[0] :\n",
      "                for j in i :\n",
      "                    df = pd.DataFrame(j)\n",
      "                    df.columns = [c[0].lower() for c in df.columns]\n",
      "                    df = df[ sorted(df.columns.values.tolist()) ] # make sure columns are sorted\n",
      "                    # extract 'file' (in variable depth list of lists)\n",
      "                    tmp_file = df.iloc[0,1]\n",
      "                    while len(np.shape(tmp_file)) > 1 : # i.e. not 1D\n",
      "                        tmp_file = tmp_file[0] # iteratively flatten\n",
      "                    tmp_file = tmp_file.flat[0]\n",
      "                    if type(tmp_file) is np.ndarray :\n",
      "                        tmp_file = str(tmp_file.flat[0])\n",
      "                    tmp.extend(\n",
      "                                [\n",
      "                                pd.concat(\n",
      "                                    [\n",
      "                                        pd.DataFrame(df.iloc[:,0].tolist()[0], columns=['x', 'y', 'z']), # accel data\n",
      "                                        pd.DataFrame({'time' : [e[0] for e in df.iloc[:,2][0]], 'file' : tmp_file})\n",
      "                                     ], axis=1, ignore_index=True\n",
      "                                    )\n",
      "                                ]\n",
      "                            )\n",
      "\n",
      "            #tmp = pd.concat([pd.DataFrame(i) for i in v[1]])\n",
      "        else :\n",
      "            tmp.extend([pd.DataFrame(v)])\n",
      "\n",
      "    # concat dataframe and return\n",
      "    tmp = pd.concat(tmp)\n",
      "    return(tmp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_file(f):\n",
      "    \n",
      "    print(\"Reading in file {}\".format(f))\n",
      "    tmp = None\n",
      "    \n",
      "    # skip output file if it already exists\n",
      "    if os.path.basename(f) == 'test_data_full.tsv' or os.path.basename(f) == 'test_data_small.tsv':\n",
      "        print(\"\\tNot processing\")\n",
      "        return(None)\n",
      "\n",
      "    # parse file depending on the file extension\n",
      "    if os.path.splitext(f)[1] == \".mat\":\n",
      "        tmp = process_mat_file(f)\n",
      "    elif os.path.splitext(f)[1] == \".csv\":\n",
      "        tmp = pd.read_csv(f)\n",
      "    elif os.path.splitext(f)[1] == \".tsv\":\n",
      "        tmp = pd.read_csv(f, sep=\"\\t\")\n",
      "    elif os.path.splitext(f)[1] == \".txt\":\n",
      "        ## assume semi-colons\n",
      "        tmp = pd.read_csv(f, sep=\";\")\n",
      "    else :\n",
      "        print(\"\\tFile cannot be read.\")\n",
      "        \n",
      "    # collect data if we got some\n",
      "    if tmp is not None :\n",
      "        # add new column for file and clean up\n",
      "        tmp['src'] = os.path.basename(f)\n",
      "        if VERBOSE: print(np.shape(tmp))\n",
      "        return(tmp)\n",
      "    else :\n",
      "        print(\"\\tNothing to return\")\n",
      "        return(None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# collect all files from data directory\n",
      "files = [ join(datapath,f) for f in os.listdir(datapath) if isfile(join(datapath,f)) ]\n",
      "# report files found and read them in\n",
      "accel = [ process_file(f) for f in files ]\n",
      "accel = [ a for a in accel if a is not None ] # drop files that did not process"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\desktop.ini\n",
        "\tFile cannot be read.\n",
        "\tNothing to return\n",
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\error_1.mat\n",
        "(4088167, 6)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\error_2.mat\n",
        "(11540660, 6)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\test_1.mat\n",
        "(14015, 5)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\test_2.txt\n",
        "(199520, 5)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Reading in file C:\\Users\\Ieuan and Katharina\\ieuan_work\\delft\\dataQC\\test_data\\test_data_full.tsv\n",
        "\tNot processing\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## re-parse data into pandas structure and clean up\n",
      "if TEST :\n",
      "    if VERBOSE :\n",
      "        print(\">>> BEFORE\")\n",
      "        for a in accel:\n",
      "            print(\"TYPE\")\n",
      "            print(type(a))\n",
      "            print(\"HEAD\")\n",
      "            print(a.head(2))\n",
      "            print(\"INFO\")\n",
      "            print(a.info())\n",
      "\n",
      "    ### dirty hack to get formats the same, \n",
      "    ### would be better if formats actually matched or where distinguishable \n",
      "    ### based on file extension or header, etc\n",
      "\n",
      "    for (i, k) in enumerate(accel) :\n",
      "        #error_1.mat\n",
      "        #error_2.mat\n",
      "        #test_1.mat\n",
      "        #test_2.txt\n",
      "        if k.iloc[0][\"src\"] == \"error_1.mat\" :\n",
      "            k.columns = [\"x\", \"y\", \"z\", \"file\", \"t\", \"src\"]\n",
      "            k.set_index([\"src\", \"file\"], inplace=True)\n",
      "        elif k.iloc[0][\"src\"] == \"error_2.mat\" :\n",
      "            k.columns = [\"x\", \"y\", \"z\", \"file\", \"t\", \"src\"] \n",
      "            k.set_index([\"src\", \"file\"], inplace=True)\n",
      "        elif k.iloc[0][\"src\"] == \"test_1.mat\" :\n",
      "            k.columns = [\"x\", \"y\", \"z\", \"t\", \"src\"]\n",
      "            k[\"file\"] = None # add new empty placeholder\n",
      "            # reset time to 20Hz\n",
      "            k.drop(['t'], axis=1,inplace=True)\n",
      "            k['t'] = pd.Series(np.arange(np.shape(k)[0])/20)\n",
      "            k.set_index([\"src\", \"file\"], inplace=True)\n",
      "        elif k.iloc[0][\"src\"] == \"test_2.txt\" :\n",
      "            k.columns = [\"t\", \"x\", \"y\", \"z\", \"src\"]\n",
      "            k[\"file\"] = None # add new empty placeholder\n",
      "            k.set_index([\"src\", \"file\"], inplace=True)\n",
      "    \n",
      "    if VERBOSE: \n",
      "        print(\">>> AFTER\")\n",
      "        for a in accel:\n",
      "            print(\"TYPE\")\n",
      "            print(type(a))\n",
      "            print(\"HEAD\")\n",
      "            print(a.head())\n",
      "            print(\"INFO\")\n",
      "            print(a.info())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> BEFORE\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "    0    1    2         3    4          src\n",
        "0  35  461  745  4097.log  0.0  error_1.mat\n",
        "1  35  461  745  4097.log  0.1  error_1.mat"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 4088167 entries, 0 to 131880\n",
        "Data columns (total 6 columns):\n",
        "0      int16\n",
        "1      int16\n",
        "2      int16\n",
        "3      object\n",
        "4      float64\n",
        "src    object\n",
        "dtypes: float64(1), int16(3), object(2)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "      0      1      2                     3     4          src\n",
        "0  8979 -27136 -25601  accel_node000001.csv  1.00  error_2.mat\n",
        "1  8960 -26881 -25853  accel_node000001.csv  1.05  error_2.mat\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 11540660 entries, 0 to 263399\n",
        "Data columns (total 6 columns):\n",
        "0      int16\n",
        "1      int16\n",
        "2      int16\n",
        "3      object\n",
        "4      float64\n",
        "src    object\n",
        "dtypes: float64(1), int16(3), object(2)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "          0         1         2   3         src\n",
        "0 -0.060333  9.759333  4.559333  20  test_1.mat\n",
        "1 -0.245000  9.544000  4.141000  20  test_1.mat\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 14015 entries, 0 to 14014\n",
        "Data columns (total 5 columns):\n",
        "0      14015 non-null float64\n",
        "1      14015 non-null float64\n",
        "2      14015 non-null float64\n",
        "3      14015 non-null float64\n",
        "src    14015 non-null object\n",
        "dtypes: float64(4), object(1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "   time     x    y      z         src\n",
        "0  1.00  1044  256 -12288  test_2.txt\n",
        "1  1.05  1024  256 -12289  test_2.txt\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 199520 entries, 0 to 199519\n",
        "Data columns (total 5 columns):\n",
        "time    199520 non-null float64\n",
        "x       199520 non-null int64\n",
        "y       199520 non-null int64\n",
        "z       199520 non-null int64\n",
        "src     199520 non-null object\n",
        "dtypes: float64(1), int64(3), object(1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        ">>> AFTER"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "                       x    y    z    t\n",
        "src         file                       \n",
        "error_1.mat 4097.log  35  461  745  0.0\n",
        "            4097.log  35  461  745  0.1\n",
        "            4097.log  35  497  781  0.2\n",
        "            4097.log   0  497  745  0.3\n",
        "            4097.log  71  497  710  0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "MultiIndex: 4088167 entries, (error_1.mat, 4097.log) to (error_1.mat, 4158.log)\n",
        "Data columns (total 4 columns):\n",
        "x    int16\n",
        "y    int16\n",
        "z    int16\n",
        "t    float64\n",
        "dtypes: float64(1), int16(3)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "                                      x      y      z     t\n",
        "src         file                                           \n",
        "error_2.mat accel_node000001.csv   8979 -27136 -25601  1.00\n",
        "            accel_node000001.csv   8960 -26881 -25853  1.05\n",
        "            accel_node000001.csv  18176  29439 -25853  1.10\n",
        "            accel_node000001.csv  18176 -17921  30467  1.15\n",
        "            accel_node000001.csv   8960 -17921  30467  1.20\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "MultiIndex: 11540660 entries, (error_2.mat, accel_node000001.csv) to (error_2.mat, accel_node000106.csv)\n",
        "Data columns (total 4 columns):\n",
        "x    int16\n",
        "y    int16\n",
        "z    int16\n",
        "t    float64\n",
        "dtypes: float64(1), int16(3)None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "                        x         y         z     t\n",
        "src        file                                    \n",
        "test_1.mat NaN  -0.060333  9.759333  4.559333  0.00\n",
        "           NaN  -0.245000  9.544000  4.141000  0.05\n",
        "           NaN  -0.186667  9.492333  3.850000  0.10\n",
        "           NaN  -0.147000  9.586000  3.972000  0.15\n",
        "           NaN  -0.233000  9.483000  4.140000  0.20\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "MultiIndex: 14015 entries, (test_1.mat, nan) to (test_1.mat, nan)\n",
        "Data columns (total 4 columns):\n",
        "x    14015 non-null float64\n",
        "y    14015 non-null float64\n",
        "z    14015 non-null float64\n",
        "t    14015 non-null float64\n",
        "dtypes: float64(4)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "TYPE\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "HEAD\n",
        "                    t     x    y      z\n",
        "src        file                        \n",
        "test_2.txt NaN   1.00  1044  256 -12288\n",
        "           NaN   1.05  1024  256 -12289\n",
        "           NaN   1.10  1024  256 -12289\n",
        "           NaN   1.15   768  256 -12289\n",
        "           NaN   1.20  1024  256 -12289\n",
        "INFO\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "MultiIndex: 199520 entries, (test_2.txt, nan) to (test_2.txt, nan)\n",
        "Data columns (total 4 columns):\n",
        "t    199520 non-null float64\n",
        "x    199520 non-null int64\n",
        "y    199520 non-null int64\n",
        "z    199520 non-null int64\n",
        "dtypes: float64(1), int64(3)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## combine and save data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# combine\n",
      "accel = pd.concat(accel)\n",
      "accel.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "MultiIndex: 15842362 entries, (error_1.mat, 4097.log) to (test_2.txt, nan)\n",
        "Data columns (total 4 columns):\n",
        "t    float64\n",
        "x    float64\n",
        "y    float64\n",
        "z    float64\n",
        "dtypes: float64(4)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# subset and print\n",
      "#accel.to_csv('test_data/test_data_full.tsv', sep=\"\\t\", index=True, header=True)\n",
      "pd.concat([     \n",
      "    accel.loc[('error_1.mat','4097.log'):('error_1.mat','4099.log'),:], \n",
      "    accel.loc[('error_2.mat','accel_node000001.csv'):('error_2.mat','accel_node000003.csv'),:],\n",
      "    accel.loc[('test_2.txt', 'nan'):('test_2.txt', 'nan'),:]\n",
      "              ]).to_csv('test_data/test_data_small.tsv', sep=\"\\t\", index=True, header=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}